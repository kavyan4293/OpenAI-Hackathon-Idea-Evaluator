from transformers import GPTNeoForCausalLM, GPT2Tokenizer

def generate_evaluation(problem, solution):
    text = f"Problem: {problem}\nSolution: {solution}"
    model_name = "EleutherAI/gpt-neo-1.3B"  # You can adjust the model size as needed
    tokenizer = GPT2Tokenizer.from_pretrained(model_name)
    model = GPTNeoForCausalLM.from_pretrained(model_name)

    input_ids = tokenizer.encode(text, return_tensors='pt')
    output = model.generate(input_ids, max_length=200, num_beams=5, no_repeat_ngram_size=2, top_k=50, top_p=0.95, temperature=0.7)

    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)
    return generated_text

# Example usage
problem = "The construction industry produces 1.3 billion tons of waste annually."
solution = "Introduce modular construction to reduce waste by 90% and decrease construction time by 30-50%."
evaluation = generate_evaluation(problem, solution)
print(evaluation)
