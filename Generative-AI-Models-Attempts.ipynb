{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bce9e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>problem</th>\n",
       "      <th>solution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The construction industry is indubitably one o...</td>\n",
       "      <td>Herein, we propose an innovative approach to m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>I'm sure you, like me, are feeling the heat - ...</td>\n",
       "      <td>Imagine standing on a green hill, not a single...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The massive shift in student learning towards ...</td>\n",
       "      <td>Implement a \"\"Book Swap\"\" program within educa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The fashion industry is one of the top contrib...</td>\n",
       "      <td>The proposed solution is a garment rental serv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The majority of the materials used in producin...</td>\n",
       "      <td>An innovative concept would be a modular elect...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            problem  \\\n",
       "0   1  The construction industry is indubitably one o...   \n",
       "1   2  I'm sure you, like me, are feeling the heat - ...   \n",
       "2   3  The massive shift in student learning towards ...   \n",
       "3   4  The fashion industry is one of the top contrib...   \n",
       "4   5  The majority of the materials used in producin...   \n",
       "\n",
       "                                            solution  \n",
       "0  Herein, we propose an innovative approach to m...  \n",
       "1  Imagine standing on a green hill, not a single...  \n",
       "2  Implement a \"\"Book Swap\"\" program within educa...  \n",
       "3  The proposed solution is a garment rental serv...  \n",
       "4  An innovative concept would be a modular elect...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline, BertTokenizer, BertForQuestionAnswering\n",
    "problem_solv = pd.read_csv(\"Dataset1.csv\")\n",
    "problem_solv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c52d1443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: [CLS]\n"
     ]
    }
   ],
   "source": [
    "#DistilBERT\n",
    "from transformers import DistilBertTokenizer, DistilBertForQuestionAnswering\n",
    "import torch\n",
    "\n",
    "def answer_question(context, question):\n",
    "    # Load pre-trained DistilBERT model and tokenizer\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased-distilled-squad')\n",
    "    model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-cased-distilled-squad')\n",
    "\n",
    "    # Tokenize input text\n",
    "    inputs = tokenizer(context, question, return_tensors=\"pt\", truncation=True)\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Extract start and end logits from the model's output\n",
    "    start_logits = outputs.start_logits\n",
    "    end_logits = outputs.end_logits\n",
    "\n",
    "    # Get the most probable start and end indices\n",
    "    start_index = torch.argmax(start_logits, dim=1).item()\n",
    "    end_index = torch.argmax(end_logits, dim=1).item()\n",
    "\n",
    "    # Decode the answer from the original text\n",
    "    answer = tokenizer.decode(inputs['input_ids'][0, start_index:end_index+1])\n",
    "\n",
    "    return answer\n",
    "\n",
    "# Example usage\n",
    "context_text = \"Herein, we propose an innovative approach to mitigate this problem: Modular Construction. This method embraces recycling and reuse, taking a significant stride towards a circular economy.   Modular construction involves utilizing engineered components in a manufacturing facility that are later assembled on-site. These components are designed for easy disassembling, enabling them to be reused in diverse projects, thus significantly reducing waste and conserving resources.  Not only does this method decrease construction waste by up to 90%, but it also decreases construction time by 30-50%, optimizing both environmental and financial efficiency. This reduction in time corresponds to substantial financial savings for businesses. Moreover, the modular approach allows greater flexibility, adapting to changing needs over time.  We believe, by adopting modular construction, the industry can transit from a take, make and dispose model to a more sustainable reduce, reuse, and recycle model, driving the industry towards a more circular and sustainable future. The feasibility of this concept is already being proven in markets around the globe, indicating its potential for scalability and real-world application.\"\n",
    "question_text = \"The construction industry is indubitably one of the significant contributors to global waste, contributing approximately 1.3 billion tons of waste annually, exerting significant pressure on our landfills and natural resources. Traditional construction methods entail single-use designs that require frequent demolitions, leading to resource depletion and wastage.\"\n",
    "\n",
    "answer = answer_question(context_text, question_text)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "827839ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForQuestionAnswering: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  economy.   Modular construction involves utilizing engineered components in a manufacturing facility that are later assembled on-site. These components are designed for easy disassembling, enabling them to be reused in diverse projects, thus significantly reducing waste and conserving resources.  Not only does this method decrease construction waste by up to 90%, but it also decreases construction time by 30-50%, optimizing both environmental and financial efficiency. This reduction in time corresponds to substantial financial savings for businesses. Moreover, the modular approach allows greater flexibility, adapting to changing needs over time.  We believe, by adopting modular construction, the industry can transit from a take,\n"
     ]
    }
   ],
   "source": [
    "#RoBERTa\n",
    "from transformers import RobertaTokenizer, RobertaForQuestionAnswering\n",
    "import torch\n",
    "\n",
    "def answer_question(context, question):\n",
    "    # Load pre-trained DistilBERT model and tokenizer\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    model = RobertaForQuestionAnswering.from_pretrained('roberta-base')\n",
    "\n",
    "    # Tokenize input text\n",
    "    inputs = tokenizer(context, question, return_tensors=\"pt\", truncation=True)\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Extract start and end logits from the model's output\n",
    "    start_logits = outputs.start_logits\n",
    "    end_logits = outputs.end_logits\n",
    "\n",
    "    # Get the most probable start and end indices\n",
    "    start_index = torch.argmax(start_logits, dim=1).item()\n",
    "    end_index = torch.argmax(end_logits, dim=1).item()\n",
    "\n",
    "    # Decode the answer from the original text\n",
    "    answer = tokenizer.decode(inputs['input_ids'][0, start_index:end_index+1])\n",
    "\n",
    "    return answer\n",
    "\n",
    "# Example usage\n",
    "context_text = \"Herein, we propose an innovative approach to mitigate this problem: Modular Construction. This method embraces recycling and reuse, taking a significant stride towards a circular economy.   Modular construction involves utilizing engineered components in a manufacturing facility that are later assembled on-site. These components are designed for easy disassembling, enabling them to be reused in diverse projects, thus significantly reducing waste and conserving resources.  Not only does this method decrease construction waste by up to 90%, but it also decreases construction time by 30-50%, optimizing both environmental and financial efficiency. This reduction in time corresponds to substantial financial savings for businesses. Moreover, the modular approach allows greater flexibility, adapting to changing needs over time.  We believe, by adopting modular construction, the industry can transit from a take, make and dispose model to a more sustainable reduce, reuse, and recycle model, driving the industry towards a more circular and sustainable future. The feasibility of this concept is already being proven in markets around the globe, indicating its potential for scalability and real-world application.\"\n",
    "question_text = \"The construction industry is indubitably one of the significant contributors to global waste, contributing approximately 1.3 billion tons of waste annually, exerting significant pressure on our landfills and natural resources. Traditional construction methods entail single-use designs that require frequent demolitions, leading to resource depletion and wastage.\"\n",
    "\n",
    "answer = answer_question(context_text, question_text)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf39872b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The construction industry contributes approximately 1.3 billion tons of waste annually. The construction industry contribute\n"
     ]
    }
   ],
   "source": [
    "# T5\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "def answer_question(context, question):\n",
    "    # Load pre-trained DistilBERT model and tokenizer\n",
    "    tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "    model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
    "    \n",
    "    #input_text = f\"answer: {context} context: {question}\"\n",
    "    \n",
    "    # Tokenize input text\n",
    "    input_ids = tokenizer.encode(context, question, return_tensors='pt', truncation=True)\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(input_ids)\n",
    "\n",
    "    # Decode the generated answer from the output IDs\n",
    "    generated_answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    return generated_answer\n",
    "\n",
    "# Example usage\n",
    "context_text = \"Herein, we propose an innovative approach to mitigate this problem: Modular Construction. This method embraces recycling and reuse, taking a significant stride towards a circular economy.   Modular construction involves utilizing engineered components in a manufacturing facility that are later assembled on-site. These components are designed for easy disassembling, enabling them to be reused in diverse projects, thus significantly reducing waste and conserving resources.  Not only does this method decrease construction waste by up to 90%, but it also decreases construction time by 30-50%, optimizing both environmental and financial efficiency. This reduction in time corresponds to substantial financial savings for businesses. Moreover, the modular approach allows greater flexibility, adapting to changing needs over time.  We believe, by adopting modular construction, the industry can transit from a take, make and dispose model to a more sustainable reduce, reuse, and recycle model, driving the industry towards a more circular and sustainable future. The feasibility of this concept is already being proven in markets around the globe, indicating its potential for scalability and real-world application.\"\n",
    "question_text = \"The construction industry is indubitably one of the significant contributors to global waste, contributing approximately 1.3 billion tons of waste annually, exerting significant pressure on our landfills and natural resources. Traditional construction methods entail single-use designs that require frequent demolitions, leading to resource depletion and wastage.\"\n",
    "\n",
    "answer = answer_question(context_text, question_text)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78f0765f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForQuestionAnsweringSimple: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetForQuestionAnsweringSimple from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForQuestionAnsweringSimple from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForQuestionAnsweringSimple were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: -50%, optimizing both environmental and financial efficiency. This reduction in time corresponds to substantial financial savings for businesses. Moreover, the modular approach allows greater flexibility, adapting to changing needs over time. We believe, by adopting modular construction, the industry can transit from a take, make and dispose model to a more sustainable reduce, reuse, and recycle model, driving the industry towards a more circular and\n"
     ]
    }
   ],
   "source": [
    "# XLNet\n",
    "from transformers import XLNetTokenizer \n",
    "from transformers import XLNetForQuestionAnsweringSimple\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "\n",
    "def answer_question(context, question):\n",
    "    # Load pre-trained XLNet model and tokenizer\n",
    "    tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "    model = XLNetForQuestionAnsweringSimple.from_pretrained('xlnet-base-cased')\n",
    "\n",
    "    # Tokenize input text\n",
    "    inputs = tokenizer.encode_plus(question, context, return_tensors='pt', truncation=True)\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Get the answer span from the start and end logits\n",
    "    start_max = torch.argmax(F.softmax(outputs.start_logits, dim = -1))\n",
    "    end_max = torch.argmax(F.softmax(outputs.end_logits, dim=-1)) + 1 \n",
    "\n",
    "    # Decode the answer from the original text\n",
    "    answer = tokenizer.decode(inputs[\"input_ids\"][0][start_max : end_max])\n",
    "\n",
    "    return answer\n",
    "\n",
    "# Example usage\n",
    "#context_text = \"Herein, we propose an innovative approach to mitigate this problem: Modular Construction. This method embraces recycling and reuse, taking a significant stride towards a circular economy.   Modular construction involves utilizing engineered components in a manufacturing facility that are later assembled on-site. These components are designed for easy disassembling, enabling them to be reused in diverse projects, thus significantly reducing waste and conserving resources.  Not only does this method decrease construction waste by up to 90%, but it also decreases construction time by 30-50%, optimizing both environmental and financial efficiency. This reduction in time corresponds to substantial financial savings for businesses. Moreover, the modular approach allows greater flexibility, adapting to changing needs over time.  We believe, by adopting modular construction, the industry can transit from a take, make and dispose model to a more sustainable reduce, reuse, and recycle model, driving the industry towards a more circular and sustainable future. The feasibility of this concept is already being proven in markets around the globe, indicating its potential for scalability and real-world application.\"\n",
    "#question_text = \"The construction industry is indubitably one of the significant contributors to global waste, contributing approximately 1.3 billion tons of waste annually, exerting significant pressure on our landfills and natural resources. Traditional construction methods entail single-use designs that require frequent demolitions, leading to resource depletion and wastage.\"\n",
    "\n",
    "answer = answer_question(context_text, question_text)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e75e6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForQuestionAnsweringSimple: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetForQuestionAnsweringSimple from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForQuestionAnsweringSimple from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForQuestionAnsweringSimple were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForQuestionAnsweringSimple: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetForQuestionAnsweringSimple from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForQuestionAnsweringSimple from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForQuestionAnsweringSimple were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForQuestionAnsweringSimple: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetForQuestionAnsweringSimple from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForQuestionAnsweringSimple from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForQuestionAnsweringSimple were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForQuestionAnsweringSimple: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetForQuestionAnsweringSimple from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForQuestionAnsweringSimple from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForQuestionAnsweringSimple were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForQuestionAnsweringSimple: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetForQuestionAnsweringSimple from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForQuestionAnsweringSimple from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForQuestionAnsweringSimple were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForQuestionAnsweringSimple: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetForQuestionAnsweringSimple from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForQuestionAnsweringSimple from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForQuestionAnsweringSimple were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForQuestionAnsweringSimple: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetForQuestionAnsweringSimple from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForQuestionAnsweringSimple from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForQuestionAnsweringSimple were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForQuestionAnsweringSimple: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetForQuestionAnsweringSimple from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForQuestionAnsweringSimple from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLNetForQuestionAnsweringSimple were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForQuestionAnsweringSimple: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetForQuestionAnsweringSimple from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForQuestionAnsweringSimple from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForQuestionAnsweringSimple were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForQuestionAnsweringSimple: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetForQuestionAnsweringSimple from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForQuestionAnsweringSimple from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForQuestionAnsweringSimple were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "# XLNet\n",
    "from transformers import XLNetTokenizer \n",
    "from transformers import XLNetForQuestionAnsweringSimple\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "\n",
    "def answer_question(row):\n",
    "    # Load pre-trained XLNet model and tokenizer\n",
    "    tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "    model = XLNetForQuestionAnsweringSimple.from_pretrained('xlnet-base-cased')\n",
    "\n",
    "    # Tokenize input text\n",
    "    inputs = tokenizer.encode_plus(row['problem'], row['solution'], return_tensors='pt', truncation=True)\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Get the answer span from the start and end logits\n",
    "    start_max = torch.argmax(F.softmax(outputs.start_logits, dim = -1))\n",
    "    end_max = torch.argmax(F.softmax(outputs.end_logits, dim=-1)) + 1 \n",
    "\n",
    "    # Decode the answer from the original text\n",
    "    answer = tokenizer.decode(inputs[\"input_ids\"][0][start_max : end_max])\n",
    "\n",
    "    return answer\n",
    "\n",
    "# Example usage\n",
    "#context_text = \"Herein, we propose an innovative approach to mitigate this problem: Modular Construction. This method embraces recycling and reuse, taking a significant stride towards a circular economy.   Modular construction involves utilizing engineered components in a manufacturing facility that are later assembled on-site. These components are designed for easy disassembling, enabling them to be reused in diverse projects, thus significantly reducing waste and conserving resources.  Not only does this method decrease construction waste by up to 90%, but it also decreases construction time by 30-50%, optimizing both environmental and financial efficiency. This reduction in time corresponds to substantial financial savings for businesses. Moreover, the modular approach allows greater flexibility, adapting to changing needs over time.  We believe, by adopting modular construction, the industry can transit from a take, make and dispose model to a more sustainable reduce, reuse, and recycle model, driving the industry towards a more circular and sustainable future. The feasibility of this concept is already being proven in markets around the globe, indicating its potential for scalability and real-world application.\"\n",
    "#question_text = \"The construction industry is indubitably one of the significant contributors to global waste, contributing approximately 1.3 billion tons of waste annually, exerting significant pressure on our landfills and natural resources. Traditional construction methods entail single-use designs that require frequent demolitions, leading to resource depletion and wastage.\"\n",
    "\n",
    "problem_solv['soln_extract'] = problem_solv.apply(answer_question, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1bf563bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>problem</th>\n",
       "      <th>solution</th>\n",
       "      <th>soln_extract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The construction industry is indubitably one o...</td>\n",
       "      <td>Herein, we propose an innovative approach to m...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>I'm sure you, like me, are feeling the heat - ...</td>\n",
       "      <td>Imagine standing on a green hill, not a single...</td>\n",
       "      <td>the heat - literally! With World Health Organi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The massive shift in student learning towards ...</td>\n",
       "      <td>Implement a \"\"Book Swap\"\" program within educa...</td>\n",
       "      <td>-waste from obsolete devices. Simultaneously, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The fashion industry is one of the top contrib...</td>\n",
       "      <td>The proposed solution is a garment rental serv...</td>\n",
       "      <td>, leading to the release of greenhouse gases f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The majority of the materials used in producin...</td>\n",
       "      <td>An innovative concept would be a modular elect...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Businesses worldwide expend substantial financ...</td>\n",
       "      <td>The proposed solution involves developing a se...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>more than 130 Billon plastic bottles waste ann...</td>\n",
       "      <td>Bariq factory to recyle plastic bottels</td>\n",
       "      <td>130 Billon plastic bottles waste annualy in Eg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>In congested cities like Berlin, one of the si...</td>\n",
       "      <td>Let's revolutionize the carsharing experience...</td>\n",
       "      <td>\"\"Ride-sharing Radar\"\" - Your carpooling maest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>One major global issue we face today is the su...</td>\n",
       "      <td>My solution is an innovative Reloop - System, ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>The usage of plastic bottles</td>\n",
       "      <td>Creating a service that sells bottles, and re-...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            problem  \\\n",
       "0   1  The construction industry is indubitably one o...   \n",
       "1   2  I'm sure you, like me, are feeling the heat - ...   \n",
       "2   3  The massive shift in student learning towards ...   \n",
       "3   4  The fashion industry is one of the top contrib...   \n",
       "4   5  The majority of the materials used in producin...   \n",
       "5   6  Businesses worldwide expend substantial financ...   \n",
       "6   7  more than 130 Billon plastic bottles waste ann...   \n",
       "7   8  In congested cities like Berlin, one of the si...   \n",
       "8   9  One major global issue we face today is the su...   \n",
       "9  10                       The usage of plastic bottles   \n",
       "\n",
       "                                            solution  \\\n",
       "0  Herein, we propose an innovative approach to m...   \n",
       "1  Imagine standing on a green hill, not a single...   \n",
       "2  Implement a \"\"Book Swap\"\" program within educa...   \n",
       "3  The proposed solution is a garment rental serv...   \n",
       "4  An innovative concept would be a modular elect...   \n",
       "5  The proposed solution involves developing a se...   \n",
       "6            Bariq factory to recyle plastic bottels   \n",
       "7   Let's revolutionize the carsharing experience...   \n",
       "8  My solution is an innovative Reloop - System, ...   \n",
       "9  Creating a service that sells bottles, and re-...   \n",
       "\n",
       "                                        soln_extract  \n",
       "0                                                     \n",
       "1  the heat - literally! With World Health Organi...  \n",
       "2  -waste from obsolete devices. Simultaneously, ...  \n",
       "3  , leading to the release of greenhouse gases f...  \n",
       "4                                                     \n",
       "5                                                     \n",
       "6  130 Billon plastic bottles waste annualy in Eg...  \n",
       "7  \"\"Ride-sharing Radar\"\" - Your carpooling maest...  \n",
       "8                                                     \n",
       "9                                                     "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_solv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4a6b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual Cleaning and Pre processing of the Solutions using NLP methods\n",
    "import re\n",
    "import punctuation from string\n",
    "string.punctuation\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "for i in problem_solv.index:\n",
    "    sampl_sents = sent_tokenize(sampl_punct2)\n",
    "    sampl_words = [word_tokenize(sent) for sent in sampl_sents]\n",
    "    text_nonpunct = [char for char in sampl_words if char not in string.punctuation]\n",
    "    customStopWords = set(stopwords.words('english')+list(punctuation))\n",
    "    sampl_nostopwords = [word for word in word_tokenize(text_nonpunct) if word not in customStopWords]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
